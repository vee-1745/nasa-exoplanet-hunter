{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib\n",
    "\n",
    "# Import our primary tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# A setting to make our plots look nicer\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d324850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# You will need to change the filename to match the one you downloaded.\n",
    "# Try to read with default options, but skip bad lines if parsing fails\n",
    "file_path = '../data/cumulative_2025.10.04_00.14.27.csv'\n",
    "koi_data = pd.read_csv(file_path, on_bad_lines='skip', engine='python')\n",
    "\n",
    "print(\"Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the table\n",
    "koi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values in our target column\n",
    "# Make sure cell 4 (which reloads koi_data with the correct header) has been run before this cell\n",
    "koi_data['koi_disposition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb35051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the CSV with the correct header row (skip comment lines)\n",
    "# The actual data header is likely at line 51 (0-based index), so header=51\n",
    "koi_data = pd.read_csv(file_path, comment='#', header=0, engine='python')\n",
    "\n",
    "# Let's plot Orbital Period vs. Planet Radius for CONFIRMED exoplanets\n",
    "confirmed_planets = koi_data[koi_data['koi_disposition'] == 'CONFIRMED']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(confirmed_planets['koi_period'], confirmed_planets['koi_prad'], alpha=0.5, s=10)\n",
    "\n",
    "# Use a log scale for better visibility of the distribution\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.title('NASA Kepler Confirmed Exoplanets')\n",
    "plt.xlabel('Orbital Period (days)')\n",
    "plt.ylabel('Planet Radius (Earth Radii)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of promising features\n",
    "features = [\n",
    "    'koi_period',        # Orbital Period (days)\n",
    "    'koi_duration',      # Transit Duration (hours)\n",
    "    'koi_depth',         # Transit Depth (parts per million)\n",
    "    'koi_prad',          # Planetary Radius (Earth radii)\n",
    "    'koi_steff',         # Stellar Effective Temperature (Kelvin)\n",
    "    'koi_slogg',         # Stellar Surface Gravity (log10(cm/s^2))\n",
    "    'koi_srad',          # Stellar Radius (Solar radii)\n",
    "    'koi_disposition'    # The target label we want to predict\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with only these features\n",
    "df_clean = koi_data[features].copy()\n",
    "\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the 'CANDIDATE' entries\n",
    "df_clean = df_clean[df_clean['koi_disposition'] != 'CANDIDATE']\n",
    "\n",
    "# Create a numerical mapping for our target\n",
    "disposition_map = {'CONFIRMED': 1, 'FALSE POSITIVE': 0}\n",
    "df_clean['koi_disposition'] = df_clean['koi_disposition'].map(disposition_map)\n",
    "\n",
    "# Check the new distribution\n",
    "df_clean['koi_disposition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_clean' not in locals():\n",
    "\tprint(\"Variable 'df_clean' is not defined. Please run the previous data cleaning cells first.\")\n",
    "else:\n",
    "\t# 'X' contains all our feature columns\n",
    "\tX = df_clean.drop('koi_disposition', axis=1)\n",
    "\n",
    "\t# 'y' contains the target column\n",
    "\ty = df_clean['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd392465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check if X and y are defined\n",
    "if 'X' not in locals() or 'y' not in locals():\n",
    "\tprint(\"Variables X and y are not defined. Please run the cell that defines X and y (cell 8) first.\")\n",
    "else:\n",
    "\t# Split the data into training and testing sets\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\t# stratify=y ensures that the proportion of confirmed planets and false positives is the same in both the train and test sets.\n",
    "\t# random_state=42 ensures we get the same split every time we run the code.\n",
    "\n",
    "\tprint(f\"Training data shape: {X_train.shape}\")\n",
    "\tprint(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Check if X_train and y_train are defined\n",
    "if 'X_train' not in locals() or 'y_train' not in locals():\n",
    "\tprint(\"Variables X_train and y_train are not defined. Please run the cell that splits the data (cell 9) first.\")\n",
    "else:\n",
    "\t# Create the model instance\n",
    "\t# n_estimators is the number of \"trees\" in our forest. 100 is a good starting point.\n",
    "\tmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\t# Train the model on the training data\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\n",
    "\tprint(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec43ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Use the trained model to make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\n---------------------------------------\\n\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, target_names=['False Positive', 'Confirmed Planet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3398290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Model saved successfully to 'model/exoplanet_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "%pip install joblib\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create a directory to store the model if it doesn't exist\n",
    "if not os.path.exists('../model'):\n",
    "    os.makedirs('../model')\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(upgraded_model, '../model/exoplanet_model.joblib')\n",
    "\n",
    "print(\"Model saved successfully to 'model/exoplanet_model.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a50c9d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kepler (KOI) Shape: (9564, 49)\n",
      "K2 Shape: (4004, 94)\n",
      "TESS (TOI) Shape: (7703, 65)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "# Make sure to update the filenames to match what you have in your 'data' folder\n",
    "df_koi = pd.read_csv('../data/cumulative_2025.10.04_00.14.27.csv', comment='#')\n",
    "df_k2 = pd.read_csv('../data/k2pandc_2025.10.04_22.22.53.csv', comment='#')\n",
    "df_tess = pd.read_csv('../data/TOI_2025.10.04_22.22.47.csv', comment='#')\n",
    "\n",
    "print(\"Kepler (KOI) Shape:\", df_koi.shape)\n",
    "print(\"K2 Shape:\", df_k2.shape)\n",
    "print(\"TESS (TOI) Shape:\", df_tess.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29e9dbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2 columns: ['pl_name', 'hostname', 'default_flag', 'disposition', 'disp_refname', 'sy_snum', 'sy_pnum', 'discoverymethod', 'disc_year', 'disc_facility', 'soltype', 'pl_controv_flag', 'pl_refname', 'pl_orbper', 'pl_orbpererr1', 'pl_orbpererr2', 'pl_orbperlim', 'pl_orbsmax', 'pl_orbsmaxerr1', 'pl_orbsmaxerr2', 'pl_orbsmaxlim', 'pl_rade', 'pl_radeerr1', 'pl_radeerr2', 'pl_radelim', 'pl_radj', 'pl_radjerr1', 'pl_radjerr2', 'pl_radjlim', 'pl_bmasse', 'pl_bmasseerr1', 'pl_bmasseerr2', 'pl_bmasselim', 'pl_bmassj', 'pl_bmassjerr1', 'pl_bmassjerr2', 'pl_bmassjlim', 'pl_bmassprov', 'pl_orbeccen', 'pl_orbeccenerr1', 'pl_orbeccenerr2', 'pl_orbeccenlim', 'pl_insol', 'pl_insolerr1', 'pl_insolerr2', 'pl_insollim', 'pl_eqt', 'pl_eqterr1', 'pl_eqterr2', 'pl_eqtlim', 'ttv_flag', 'st_refname', 'st_spectype', 'st_teff', 'st_tefferr1', 'st_tefferr2', 'st_tefflim', 'st_rad', 'st_raderr1', 'st_raderr2', 'st_radlim', 'st_mass', 'st_masserr1', 'st_masserr2', 'st_masslim', 'st_met', 'st_meterr1', 'st_meterr2', 'st_metlim', 'st_metratio', 'st_logg', 'st_loggerr1', 'st_loggerr2', 'st_logglim', 'sy_refname', 'rastr', 'ra', 'decstr', 'dec', 'sy_dist', 'sy_disterr1', 'sy_disterr2', 'sy_vmag', 'sy_vmagerr1', 'sy_vmagerr2', 'sy_kmag', 'sy_kmagerr1', 'sy_kmagerr2', 'sy_gaiamag', 'sy_gaiamagerr1', 'sy_gaiamagerr2', 'rowupdate', 'pl_pubdate', 'releasedate']\n",
      "Missing columns in df_k2: ['k2_disp', 'k2_orbper', 'k2_trandur', 'k2_trandep', 'k2_rade', 'k2_teff', 'k2_logg', 'k2_rad']\n",
      "Shape of the final master dataset: (8956, 8)\n",
      "\n",
      "Distribution of classes in the master dataset:\n",
      "disposition\n",
      "0    5545\n",
      "1    3411\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_35108\\3303369053.py:62: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_master = pd.concat([df_koi_clean, df_k2_clean, df_tess_clean], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Process Kepler (KOI) Data ---\n",
    "# Select and rename columns\n",
    "df_koi_clean = df_koi[['koi_disposition', 'koi_period', 'koi_duration', 'koi_depth', 'koi_prad', 'koi_steff', 'koi_slogg', 'koi_srad']].copy()\n",
    "df_koi_clean = df_koi_clean.rename(columns={\n",
    "    'koi_disposition': 'disposition', 'koi_period': 'period', 'koi_duration': 'duration', 'koi_depth': 'depth',\n",
    "    'koi_prad': 'planet_radius', 'koi_steff': 'stellar_temp', 'koi_slogg': 'stellar_gravity', 'koi_srad': 'stellar_radius'\n",
    "})\n",
    "# Filter for our target classes and map them to 1s and 0s\n",
    "df_koi_clean = df_koi_clean[df_koi_clean['disposition'].isin(['CONFIRMED', 'FALSE POSITIVE'])]\n",
    "df_koi_clean['disposition'] = df_koi_clean['disposition'].map({'CONFIRMED': 1, 'FALSE POSITIVE': 0})\n",
    "\n",
    "\n",
    "# --- 2. Process K2 Data ---\n",
    "# Check actual column names in df_k2\n",
    "print(\"K2 columns:\", df_k2.columns.tolist())\n",
    "\n",
    "# Adjust column names below to match your actual df_k2 columns\n",
    "# Example: If your columns are ['k2_disp', 'k2_orbper', ...], update accordingly\n",
    "# For demonstration, let's use placeholder names; replace with your actual column names\n",
    "k2_columns = [\n",
    "    'k2_disp',        # disposition\n",
    "    'k2_orbper',      # period\n",
    "    'k2_trandur',     # duration\n",
    "    'k2_trandep',     # depth\n",
    "    'k2_rade',        # planet_radius\n",
    "    'k2_teff',        # stellar_temp\n",
    "    'k2_logg',        # stellar_gravity\n",
    "    'k2_rad'          # stellar_radius\n",
    "]\n",
    "\n",
    "# Only proceed if all columns exist\n",
    "missing_cols = [col for col in k2_columns if col not in df_k2.columns]\n",
    "if missing_cols:\n",
    "    print(\"Missing columns in df_k2:\", missing_cols)\n",
    "    # Create an empty DataFrame with the expected columns and correct names\n",
    "    df_k2_clean = pd.DataFrame(columns=[\n",
    "        'disposition', 'period', 'duration', 'depth',\n",
    "        'planet_radius', 'stellar_temp', 'stellar_gravity', 'stellar_radius'\n",
    "    ])\n",
    "else:\n",
    "    df_k2_clean = df_k2[k2_columns].copy()\n",
    "    df_k2_clean = df_k2_clean.rename(columns={\n",
    "        'k2_disp': 'disposition', 'k2_orbper': 'period', 'k2_trandur': 'duration', 'k2_trandep': 'depth',\n",
    "        'k2_rade': 'planet_radius', 'k2_teff': 'stellar_temp', 'k2_logg': 'stellar_gravity', 'k2_rad': 'stellar_radius'\n",
    "    })\n",
    "    df_k2_clean = df_k2_clean[df_k2_clean['disposition'].isin(['CONFIRMED', 'FALSE POSITIVE'])]\n",
    "    df_k2_clean['disposition'] = df_k2_clean['disposition'].map({'CONFIRMED': 1, 'FALSE POSITIVE': 0})\n",
    "\n",
    "\n",
    "# --- 3. Process TESS (TOI) Data ---\n",
    "df_tess_clean = df_tess[['tfopwg_disp', 'pl_orbper', 'pl_trandurh', 'pl_trandep', 'pl_rade', 'st_teff', 'st_logg', 'st_rad']].copy()\n",
    "df_tess_clean = df_tess_clean.rename(columns={\n",
    "    'tfopwg_disp': 'disposition', 'pl_orbper': 'period', 'pl_trandurh': 'duration', 'pl_trandep': 'depth',\n",
    "    'pl_rade': 'planet_radius', 'st_teff': 'stellar_temp', 'st_logg': 'stellar_gravity', 'st_rad': 'stellar_radius'\n",
    "})\n",
    "# For TESS, the labels are 'CP' (Confirmed Planet) and 'FP' (False Positive)\n",
    "df_tess_clean = df_tess_clean[df_tess_clean['disposition'].isin(['CP', 'FP'])]\n",
    "df_tess_clean['disposition'] = df_tess_clean['disposition'].map({'CP': 1, 'FP': 0})\n",
    "\n",
    "\n",
    "# --- 4. Combine into a Master DataFrame ---\n",
    "df_master = pd.concat([df_koi_clean, df_k2_clean, df_tess_clean], ignore_index=True)\n",
    "\n",
    "# --- 5. Final Cleanup ---\n",
    "# Drop any rows with missing data\n",
    "df_master = df_master.dropna()\n",
    "\n",
    "print(\"Shape of the final master dataset:\", df_master.shape)\n",
    "print(\"\\nDistribution of classes in the master dataset:\")\n",
    "print(df_master['disposition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce80b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training data shape: (6269, 7)\n",
      "New testing data shape: (2687, 7)\n",
      "\n",
      "Upgraded Model Accuracy: 86.90%\n",
      "\n",
      "New Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  False Positive       0.90      0.89      0.89      1664\n",
      "Confirmed Planet       0.82      0.84      0.83      1023\n",
      "\n",
      "        accuracy                           0.87      2687\n",
      "       macro avg       0.86      0.86      0.86      2687\n",
      "    weighted avg       0.87      0.87      0.87      2687\n",
      "\n",
      "\n",
      "Upgraded model saved successfully to 'model/exoplanet_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Define Features (X) and Target (y) ---\n",
    "# Ensure the target is numeric (0/1) and drop any rows with invalid targets\n",
    "df_master['disposition'] = pd.to_numeric(df_master['disposition'], errors='coerce')\n",
    "df_master = df_master.dropna(subset=['disposition'])\n",
    "df_master['disposition'] = df_master['disposition'].astype(int)\n",
    "\n",
    "X = df_master.drop('disposition', axis=1)\n",
    "y = df_master['disposition']\n",
    "\n",
    "# --- 2. Split Data into Training and Testing Sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"New training data shape:\", X_train.shape)\n",
    "print(\"New testing data shape:\", X_test.shape)\n",
    "\n",
    "# --- 3. Create and Train the New Model ---\n",
    "# We'll use the same Random Forest model, but it will learn from the richer dataset\n",
    "upgraded_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "upgraded_model.fit(X_train, y_train)\n",
    "\n",
    "# --- 4. Evaluate the Upgraded Model ---\n",
    "predictions = upgraded_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"\\nUpgraded Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nNew Classification Report:\")\n",
    "print(classification_report(y_test, predictions, target_names=['False Positive', 'Confirmed Planet']))\n",
    "\n",
    "# --- 5. Save the Upgraded Model ---\n",
    "# This will overwrite your old model file with the new, more powerful one\n",
    "joblib.dump(upgraded_model, '../model/exoplanet_model.joblib')\n",
    "\n",
    "print(\"\\nUpgraded model saved successfully to 'model/exoplanet_model.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
